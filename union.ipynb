{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "union.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahyagec/dimensionality-reduction/blob/master/union.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5Frbm8ZkjwWa",
        "colab_type": "code",
        "outputId": "cc34da90-8a8e-4f7d-c506-50dd33c098ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install dcor\n",
        "!pip install lightgbm\n",
        "!pip install xgboost\n",
        "!pip install catboost\n",
        "#!pip install tsfresh\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dcor in /usr/local/lib/python3.6/dist-packages (0.1.5)\r\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from dcor) (0.39.0)\r\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from dcor) (39.1.0)\r\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from dcor) (0.19.1)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dcor) (1.14.5)\r\n",
            "Requirement already satisfied: llvmlite>=0.24.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->dcor) (0.24.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U3R-QrdbhvPi",
        "colab_type": "code",
        "outputId": "8243be3f-b770-4219-b8f2-fc1062891f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import dcor\n",
        "from sklearn.cluster import KMeans as km\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFea1tures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from itertools import groupby\n",
        "import math\n",
        "import io\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "from multimethod import multimethod\n",
        "from sklearn.model_selection import RandomizedSearchCV as rscv\n",
        "\n",
        "class numerics():\n",
        "    def __init__(num =  ['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
        "        self.num = num\n",
        "    \n",
        "class AlgType(Enum):\n",
        "    xgboost_regressor = XGBRegressor()\n",
        "    xgboost_classifier = XGBClassifier()\n",
        "    lightgbm_regressor = LGBMRegressor()\n",
        "    lightgbm_classifier = LGBMClassifier()\n",
        "    catboost_regressor = CatBoostRegressor()\n",
        "    catboost_classifier = CatBoostClassifier()\n",
        "    \n",
        "class DimensionalityReduction():\n",
        "    \n",
        "    def __init__(self, raw_data, target_name, meta_data=None):\n",
        "        self.raw_data = raw_data\n",
        "        assert(isinstance(target_name, str), 'target_name must be string!') \n",
        "        self.values = raw_data.drop([target_name], axis=1) \n",
        "        self.target = raw_data[target_name]\n",
        "        self.meta_data = meta_data\n",
        "        \n",
        "        \n",
        "#    def get_data(self, target_name):\n",
        "#        assert(isinstance(target_name, str), 'target_name must be string!')\n",
        "#        values = self.raw_data.drop([target_name], axis=1) \n",
        "#        target = self.raw_data[target_name]\n",
        "#        return values, target\n",
        "\n",
        "  \n",
        "    def encoder(self, values=self.values, meta_data=self.meta_data):\n",
        "        categorics = np.array([y for x,y in meta_data['TYPE', 'VARIABLE'] if x == 'CATEGORIC'])\n",
        "        ohe = OneHotEncoder(categorical_features=categorics)\n",
        "        values = ohe.fit_transform(values)\n",
        "        self.values = values\n",
        "        return values\n",
        "        \n",
        "                \n",
        "    \n",
        "    def default_ratio(self, values=self.values, meta_data=self.meta_data, thresh=0.95, default=[0]):                         \n",
        "        res = pd.DataFrame(columns=values.columns)\n",
        "        a = default\n",
        "        for i in values:\n",
        "            if meta_data != None: \n",
        "                a = [x for x,y in meta_data['DEFAULT_VALUES', 'VARIABLE'] if y==i]\n",
        "            res[i] = 1-(values[values[i].isin(a)].count()/len(values[i]))\n",
        "            res_new = res[res[i]>thresh]\n",
        "        return values[res_new], res.columns.difference(res_new.columns), res_new.columns\n",
        "\n",
        "                         \n",
        "    def normalize(self, values=self.values, thresh=0.1):\n",
        "        values_norm = stats.zscore(values.select_dtypes(include=numerics().num))\n",
        "        b = np.argwhere(np.abs(values_norm)>3)\n",
        "        grouped_b = [list(j) for i, j in groupby(b[:,0])]\n",
        "        values_norm = pd.DataFrame(values_norm)\n",
        "        values_norm.columns = values.columns\n",
        "        for i in range(len(grouped_b)):    \n",
        "            if (len(grouped_b[i])/values_norm.shape[1]) >thresh:\n",
        "                values_norm = values_norm.drop(grouped_b[i][0], axis=0)\n",
        "        return values_norm\n",
        "\n",
        "    def reduct_low_var(self, values=self.values, threshold):\n",
        "        values = values.select_dtypes(include=numerics().num)\n",
        "        var = values.var(skipna = True)\n",
        "        res = []\n",
        "        for v in range(len(var)):\n",
        "            if var[v] >= threshold:\n",
        "                res.append(var.index.values[v]) \n",
        "        features_eliminated = choose_eliminated(values, res)    \n",
        "        return values[res], features_eliminated, res\n",
        "\n",
        "    def reduct_dcor(self, values = self.values, n_features=100): '''formatı hakkında fikir geliştirilmeli kolaylaştırıcı (fazla radikal)'''\n",
        "        values = values.select_dtypes(include=numerics().num)\n",
        "        corr = np.zeros([len(values.columns),2])\n",
        "\n",
        "        for i in range(len(values.columns)):\n",
        "            corr[i,:] = np.array([i, dcor.distance_correlation(values.iloc[:,i], target)])\n",
        "        \n",
        "        if n_features > len(corr):\n",
        "            features_chosen = values.columns[corr[:,0]]\n",
        "        else:    \n",
        "            corr = pd.DataFrame(corr).sort_values(by=corr.columns[1], ascending=False).iloc[:n_features,:] \n",
        "            corr = np.array(corr)\n",
        "            kmeans = km(n_clusters = n_features).fit(corr[:,1].reshape(-1,1))\n",
        "            labels = kmeans.labels_\n",
        "\n",
        "            x=[]\n",
        "            for l in range(n_features):\n",
        "                x.append([i for i,d in enumerate(labels) if d==l])\n",
        "\n",
        "            features_chosen = np.zeros(n_features)\n",
        "            features_chosen = features_chosen-1\n",
        "            maxx = np.zeros(n_features)\n",
        "            for l in range(len(labels)):\n",
        "                a = abs(dcor.distance_correlation(values.iloc[:,x[labels[l]]], values.iloc[:,int(corr[l,0])]))\n",
        "                if a >= maxx[labels[l]]:\n",
        "                    maxx[labels[l]] = a\n",
        "                    features_chosen[labels[l]] = corr[l,0]\n",
        "\n",
        "            features_chosen = np.array([int(i) for i in features_chosen if i>=0])\n",
        "            features_chosen = values.columns[features_chosen]\n",
        "\n",
        "        features_eliminated = choose_eliminated(values, features_chosen)\n",
        "        return values[features_chosen], features_eliminated, features_chosen\n",
        "     \n",
        "    def reduct_dcor_sqr(self, values=self.values, n_features=100):\n",
        "        values = values.select_dtypes(include=numerics().num)\n",
        "        corr = np.zeros([len(values.columns),2])\n",
        "\n",
        "        for i in range(len(values.columns)):\n",
        "            corr[i,:] = np.array([i, dcor.u_distance_correlation_sqr(values.iloc[:,i], target)])\n",
        "        \n",
        "        if n_features > len(corr):\n",
        "            features_chosen = values.columns[corr[:,0]]\n",
        "        else:    \n",
        "            corr = pd.DataFrame(corr).sort_values(by=corr.columns[1], ascending=False).iloc[:n_features,:] \n",
        "            corr = np.array(corr)\n",
        "            \n",
        "            kmeans = km(n_clusters = n_features).fit(corr[:,1].reshape(-1,1))\n",
        "            labels = kmeans.labels_\n",
        "\n",
        "            x=[]\n",
        "            for l in range(n_features):\n",
        "                x.append([i for i,d in enumerate(labels) if d==l])\n",
        "\n",
        "            features_chosen = np.zeros(n_features)\n",
        "            features_chosen = features_chosen-1\n",
        "            maxx = np.zeros(n_features)\n",
        "            for l in range(len(labels)):\n",
        "                a = abs(dcor.u_distance_correlation_sqr(values.iloc[:,x[labels[l]]], values.iloc[:,int(corr[l,0])]))\n",
        "                if a >= maxx[labels[l]]:\n",
        "                    maxx[labels[l]] = a\n",
        "                    features_chosen[labels[l]] = corr[l,0]\n",
        "\n",
        "            features_chosen = np.array([int(i) for i in features_chosen if i>=0])\n",
        "            features_chosen = values.columns[features_chosen]\n",
        "\n",
        "        features_eliminated = choose_eliminated(values, features_chosen)\n",
        "        return values[features_chosen], features_eliminated, features_chosen\n",
        "\n",
        "    def choose_eliminated(values, features_chosen):\n",
        "        values = values.drop(features_chosen, axis=1)\n",
        "        features_eliminated = values.columns\n",
        "        return features_eliminated\n",
        "\n",
        "    def assign_zero(self, values=self.values):\n",
        "        values = values.select_dtypes(include=numerics().num)\n",
        "        values_new = values.dropna(thresh=int(values.shape[1]*0.95))\n",
        "        values_new = values_new.fillna(0)\n",
        "        values_new = values_new.drop([i for i in values_new.columns if values_new[i].sum()==0], axis = 1)\n",
        "        return values_new, values.columns.difference(values_new.columns), values_new.columns\n",
        "\n",
        "    def reduct_boostedtree(self, values=self.values, target=self.target, algtype, nb_features=100):\n",
        "        model = algtype.value\n",
        "        parameters = {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1), 'kernel': ['rbf'], 'class_weight':['balanced', None]}\n",
        "        clf = rscv(model, parameters)\n",
        "        clf.fit(values, target)\n",
        "        score = clf.best_score_\n",
        "        model.fit(values, target, clf.best_params_)\n",
        "        \n",
        "        feature_weights = model.feature_importances_\n",
        "        \n",
        "        feature_weights_new = pd.DataFrame(feature_weights).sort_values(by=feature_weights.columns[1], ascending=False).iloc[:nb_features,:] \n",
        "        feature_weights_new = np.array(feature_weights)\n",
        "        \n",
        "        features_chosen = values.columns[np.transpose(np.argwhere(feature_weights_new))[0].tolist()]\n",
        "        features_eliminated = choose_eliminated(values, features_chosen)\n",
        "        return values[features_chosen], features_eliminated, features_chosen, score, feature_weights\n",
        "      \n",
        "    #def l2_regularization(values, target, degree = 10, alpha = 10):\n",
        "    #    model = Pipeline([('poly', PolynomialFeatures(degree=degree)), ('l2', Ridge(alpha=alpha))])\n",
        "    #    model = model.fit(values, target)\n",
        "    #    model.named_steps['l2'].coef_\n",
        "    #    output_features = model.get_feature_names(input_features = values.columns)\n",
        "    #    return output_features  # i have no idea what is going to pop up because of this code\n",
        "\n",
        "\n",
        "    def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
        "        '''Calculate the PSI (population stability index) across all variables\n",
        "        Args:\n",
        "           expected: numpy matrix of original values\n",
        "           actual: numpy matrix of new values, same size as expected\n",
        "           buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
        "           buckets: number of quantiles to use in bucketing variables\n",
        "           axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
        "        Returns:\n",
        "           psi_values: ndarray of psi values for each variable\n",
        "        Author:\n",
        "           Matthew Burke\n",
        "           github.com/mwburke\n",
        "           worksofchart.com\n",
        "        '''\n",
        "\n",
        "        def psi(expected_array, actual_array, buckets):\n",
        "            '''Calculate the PSI for a single variable\n",
        "            Args:\n",
        "               expected_array: numpy array of original values\n",
        "               actual_array: numpy array of new values, same size as expected\n",
        "               buckets: number of percentile ranges to bucket the values into\n",
        "            Returns:\n",
        "               psi_value: calculated PSI value\n",
        "            '''\n",
        "\n",
        "            def scale_range (input, min, max):\n",
        "                input += -(np.min(input))\n",
        "                input = input/(np.max(input) / (max - min))\n",
        "                input += min\n",
        "                return input\n",
        "\n",
        "\n",
        "            breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
        "\n",
        "            if buckettype == 'bins':\n",
        "                breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
        "            elif buckettype == 'quantiles':\n",
        "                breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
        "\n",
        "\n",
        "\n",
        "            expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
        "            actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
        "\n",
        "            def sub_psi(e_perc, a_perc):\n",
        "                '''Calculate the actual PSI value from comparing the values.\n",
        "                   Update the actual value to a very small number if equal to zero\n",
        "                '''\n",
        "                if a_perc == 0:\n",
        "                    a_perc = 0.0001\n",
        "                if e_perc == 0:\n",
        "                    e_perc = 0.0001\n",
        "\n",
        "                value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
        "                return(value)\n",
        "\n",
        "            psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
        "\n",
        "            return(psi_value)\n",
        "\n",
        "        if len(expected.shape) == 1:\n",
        "            psi_values = np.empty(len(expected.shape))\n",
        "        else:\n",
        "            psi_values = np.empty(expected.shape[axis])\n",
        "\n",
        "        for i in range(0, len(psi_values)):\n",
        "            if len(psi_values) == 1:\n",
        "                psi_values = psi(expected, actual, buckets)\n",
        "            elif axis == 0:\n",
        "                psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
        "            elif axis == 1:\n",
        "                psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
        "\n",
        "        return(psi_values)\n",
        "\n",
        "\n",
        "    def calculate_all_psi(expected,acual,buckets=10, ax=0):\n",
        "        inputs_expected = np.array(expected)\n",
        "        inpts_actual =    np.array(acual)\n",
        "\n",
        "        psi_all=pd.DataFrame(columns=['VARIABLE_INDEX','PSI_SCORE'])\n",
        "\n",
        "        for i in range(inputs_expected.shape[1]):\n",
        "            psi_i=calculate_psi(inputs_expected[:,i], inpts_actual[:,i], buckettype='bins', buckets=buckets, axis=ax)\n",
        "            psi_all.loc[i]=[i,psi_i]       \n",
        "\n",
        "        return psi_all\n",
        "\n",
        "    def reduct_psi(self, values=self.values, test=self.test, thresh = 0.8):\n",
        "        psi_all = calculate_all_psi(values, test)\n",
        "        #thresh = max(np.percentile(psi_all['PSI_SCORE'], 10), ((max(psi_all['PSI_SCORE'])-min(psi_all['PSI_SCORE']))/thresh)+min(psi_all['PSI_SCORE']))\n",
        "        features_chosen = [int(psi_all['VARIABLE_INDEX'][i]) for i in range(psi_all.shape[0]) if psi_all['PSI_SCORE'][i]<=thresh]\n",
        "        features_eliminated = choose_eliminated(values, values.columns[features_chosen])\n",
        "        return values[features_chosen], features_eliminated, features_chosen\n",
        "\n",
        " #   def rmsle(y, y_pred):    \n",
        " #       assert len(y) == len(y_pred)\n",
        " #       terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
        " #       return ((sum(terms_to_sum) * (1.0/len(y))) ** 0.5)\n",
        "\n",
        "    def reduct_sparse_rp(self, values=self.values, test=self.test, eps): '''sütunlar kayboluyor doğal olarak'''\n",
        "        values_new = 'test data is required!'\n",
        "        if test != None:\n",
        "            transformer = SparseRandomProjection(eps=eps)\n",
        "            values_new = transformer.fit_transform(values)\n",
        "        return values_new\n",
        "      \n",
        "    def solid(self, values=self.values, target=self.target, test=self.test, threshold=0, model_type):\n",
        "        if model_type==1:\n",
        "            a = self.reduct_boostedtree(values=self.values, target=self.target, algtype='xgboost_regressor', nb_features=100)\n",
        "            b = self.reduct_boostedtree(values=self.values, target=self.target, algtype='lightgbm_regressor', nb_features=100)\n",
        "            c = self.reduct_boostedtree(values=self.values, target=self.target, algtype='catboost_regressor', nb_features=100)\n",
        "            res = np.array(a[-1])/a[-2] + np.array(b[-1])/b[-2] + np.array(c[-1])/c[-2]\n",
        "            res = res[res>threshold]\n",
        "        elif model_type==2:\n",
        "            a = self.reduct_boostedtree(values=self.values, target=self.target, algtype='xgboost_classifier', nb_features=100)\n",
        "            b = self.reduct_boostedtree(values=self.values, target=self.target, algtype='lightgbm_classifier', nb_features=100)\n",
        "            c = self.reduct_boostedtree(values=self.values, target=self.target, algtype='catboost_classifier', nb_features=100)\n",
        "            res = np.array(a[-1])/a[-2] + np.array(b[-1])/b[-2] + np.array(c[-1])/c[-2]\n",
        "            res = res[res>threshold]\n",
        "        return values[res], values.columns.difference(values[res].columns), res.index \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d75d11cc6fd3>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    def __init__(num =  ['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zgi-RS2mCXUi",
        "colab_type": "code",
        "outputId": "c4ee754c-f42e-47d3-dba7-f53405530c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!pip install --upgrade -q gspread\n",
        "import gspread\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "gc = gspread.authorize(creds)\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "\n",
            "Enter verification code: ··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5J2Uip8vFaM2",
        "colab_type": "code",
        "outputId": "f429ae28-3d60-493d-8cd1-d87a44fe91a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "test = pd.read_csv('drive/ColabNotebooks/test.csv')\n",
        "train = pd.read_csv('drive/ColabNotebooks/train.csv')\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j0d_H7G3V07N",
        "colab_type": "code",
        "outputId": "48d4c9a0-4b41-4127-f03c-673b203f0a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print((res.iloc[:,0]<0).count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wcIj5vvlv9ms",
        "colab_type": "code",
        "outputId": "7f1dd32b-be94-4f45-db2b-c66cd2a3fdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1065
        }
      },
      "cell_type": "code",
      "source": [
        "values, target = get_data(train)\n",
        "values = assign_zero(values)\n",
        "#col = values.columns\n",
        "#values = reduct_sparse_rp(values, 0.3)\n",
        "#values = pd.DataFrame(values)\n",
        "#values.columns = col[:values.shape[1]]\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "\n",
        "a = reduct_low_var(values_train, 0.001)\n",
        "values_train = values_train.drop(a, axis=1)\n",
        "print(\"reductedby_low_var completed: \", a)\n",
        "#b = reduct_dcor(values_train, target_train)\n",
        "#reductedby_dcor = values_train.drop(b ,axis=1)\n",
        "#print(\"reductedby_dcor completed: \", b)\n",
        "#c = reduct_dcor_sqr(values_train, target_train)\n",
        "#reductedby_dcor_sqr = values_train.drop(c, axis=1)\n",
        "#print(\"reductedby_dcor_sqr completed: \", c)\n",
        "#d = reduct_psi(values_train, test[values_train.columns])\n",
        "#reductedby_psi = values_train.drop(d, axis=1)\n",
        "#print(\"reductedby_psi completed: \", d)\n",
        "e = reduct_xgbregressor(values_train, target_train)\n",
        "values_train = values_train.drop(e, axis=1)\n",
        "print(\"reductedby_xgbregressor completed: \", e)\n",
        "#b = reduct_dcor(values_train, target_train)\n",
        "#reductedby_dcor = values_train.drop(b ,axis=1)\n",
        "#print(\"reductedby_dcor completed: \", b)\n",
        "c = reduct_dcor_sqr(values_train, target_train)\n",
        "values_train = values_train.drop(c, axis=1)\n",
        "print(\"reductedby_dcor_sqr completed: \", c)\n",
        "#f = choose_eliminated(values_train, l2_regularization(values_train, target_train))\n",
        "#reductedby_l2 = values_train.drop(f, axis=1)\n",
        "#print(\"reductedby_l2 completed: \", f)\n",
        "\n",
        "#a = 0\n",
        "res = pd.DataFrame(columns = ['values_train'])\n",
        "\n",
        "#for i in [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr, reductedby_psi, reductedby_xgbregressor]:\n",
        "#    print(\"exporting: \", res.columns[i])\n",
        "#    file_name = str(res.columns[a] + 'sparse')\n",
        "#    sh = gc.create(file_name)\n",
        "#    worksheet = gc.open(file_name).sheet1\n",
        "#    cell_list = worksheet.range(1, 1, reducedby_low_var.shape[1], 1)\n",
        "#    a = 0\n",
        "#    for cell in cell_list:\n",
        "#        cell.value = i[a]\n",
        "#        a+=1\n",
        "#    worksheet.update_cells(cell_list)\n",
        "\n",
        "rmsl = []    \n",
        "a=0    \n",
        "for i in [values_train]:\n",
        "    model = XGBRegressor()\n",
        "    model.fit(i, target_train)\n",
        "    res.iloc[:,a] = np.array(model.predict(values_test[i.columns]))\n",
        "    rmsl.append(rmsle(target_test.tolist(), res.iloc[:,a].tolist()))\n",
        "    a += 1\n",
        "    \n",
        "print(rmsl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reductedby_low_var completed:  Index(['5d26f4d92', 'b5ad8afe0', 'cc35ec717', '5df2068b0', '34d3974de',\n",
            "       'bacadce94', '995a96a47', 'd74a5ca6d', '969d32625', '50c81fe9f',\n",
            "       '925ce0d9b', '170b48e6b', '4fcb73cb1', '4c256f2f9', 'c6776639f',\n",
            "       'dcc181073', 'f9a30f20a', '8225f7e05', 'd83a59765', '44b0a78e7',\n",
            "       '9c02efa4e', '1530f6138', 'e679b8085', '238af49a8', '210f2139a',\n",
            "       '28fbb187a', '4c41b50ad', '337153b58', '930eacbc2', '7196ddee8',\n",
            "       '19873fe8a', '22c933b9b', '224a28832', 'a8c7f5c13', 'd62a74f59',\n",
            "       '36dbda4f6', '3a743de4d', 'af1005a4f', '1548e95ae', '36c3157a7',\n",
            "       'f23c83554', '3ac1ba8f9', 'dc5ba677f', '22bf44001', '572d36d31'],\n",
            "      dtype='object')\n",
            "reductedby_xgbregressor completed:  Index(['48df886f9', '34b15f335', 'a8cb14b00', '2f0771a37', '30347e683',\n",
            "       'd08d1fbe3', '6ee66e115', 'dc5a8f1d8', '11d86fa6a', '8d6c2a0b2',\n",
            "       ...\n",
            "       'a165f5761', '9281abeea', '8675bec0b', '3a13ed79a', 'f677d4d13',\n",
            "       '71b203550', '137efaa80', 'fb36b89d9', '7e293fbaf', '9fc776466'],\n",
            "      dtype='object', length=4570)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dcor/_dcor.py:718: RuntimeWarning: overflow encountered in long_scalars\n",
            "  d_cov = (aijbij / n / (n - 3) - 2 * sum_ab / n / (n - 2) / (n - 3) +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reductedby_dcor_sqr completed:  Index(['0deb4b6a8', '77c9823f2', 'bd8f989f1', '22ed6dba3', '645b47cde',\n",
            "       'f115e74c0', '21e0e6ae3', '0a69cc2be', 'adc70e02f', '039b8bbc6',\n",
            "       'ef4b87773', '2ca23426b', '47cd6e6e4', '9a3a1d59b', 'bee629024',\n",
            "       '1d9078f84', 'c3c633f64', '8337d1adc', 'dc3b4460b', 'b94360a3b',\n",
            "       'aa164b93b', '4edc3388d', 'ede70bfea', '64e483341', '1ba077222',\n",
            "       'edc84139a', 'bb1113dbb', '26df61cc3', 'b4da814b8', '7ab926448',\n",
            "       '9a9fc1aba', 'dd84674d0', 'f32763afc', '2e7f340f2', 'c1ad8b95a',\n",
            "       '5f341a818', '9884166a7', 'c2dae3a5a', 'a60974604', 'e16a20511',\n",
            "       '0929d922b', '215c4d496', '36a131c2c', 'd3022e2f1', '2862eec4f',\n",
            "       'db147ffca', '540208409', '61c1b7eb6', 'cd7f0affd', 'a8b721722',\n",
            "       '06f6a7287', '400e9303d', '56cb93fd8', 'fbe583de5', '84067cfe0',\n",
            "       '58ed8fb53', '4824c1e90', '5f6ea2fa9', 'fc436be29', 'f1e0ada11',\n",
            "       '939f628a7', '899dbe405', '191e21b5f', '879e1f51a', 'bf6e38e39',\n",
            "       '26628e8d8', '2a83c3267', 'e53805953', '3e37bffde', '2fc60d4d9',\n",
            "       '73687e512', '4e5da0e96', 'c8a66413e', '0c8063d63', '5fb9cabb1',\n",
            "       'b379107b3', 'fe919be32', 'a396ceeb9', '3ecc09859'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-abed41f612c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mrmsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-53a43e460049>\u001b[0m in \u001b[0;36mrmsle\u001b[0;34m(y, y_pred)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mterms_to_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_to_sum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-53a43e460049>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mterms_to_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_to_sum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JUYqEqFlsmvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = assign_zero(values_train)\n",
        "values_train = normalize(values_train, 0.2)\n",
        "values_test = values_test[values_train.columns]\n",
        "\n",
        "a = reduct_low_var(values_train, 0.001)\n",
        "reductedby_low_var = values_train.drop(a, axis=1)\n",
        "print(\"reductedby_low_var completed: \", a)\n",
        "#b = reduct_dcor(values_train, target_train)\n",
        "#reductedby_dcor = values_train.drop(b ,axis=1)\n",
        "#print(\"reductedby_dcor completed: \", b)\n",
        "#c = reduct_dcor_sqr(values_train, target_train)\n",
        "#reductedby_dcor_sqr = values_train.drop(c, axis=1)\n",
        "#print(\"reductedby_dcor_sqr completed: \", c)\n",
        "d = reduct_psi(values_train, test[values_train.columns])\n",
        "reductedby_psi = values_train.drop(d, axis=1)\n",
        "print(\"reductedby_psi completed: \", d)\n",
        "e = reduct_xgbregressor(values_train, target_train)\n",
        "reductedby_xgbregressor = values_train.drop(e, axis=1)\n",
        "print(\"reductedby_xgbregressor completed: \", e)\n",
        "#f = choose_eliminated(values_train, l2_regularization(values_train, target_train))\n",
        "#reductedby_l2 = values_train.drop(f, axis=1)\n",
        "#print(\"reductedby_l2 completed: \", f)\n",
        "\n",
        "a = 0\n",
        "res = pd.DataFrame(columns = ['reductedby_low_var',''' 'reductedby_dcor', 'reductedby_dcor_sqr',''' 'reductedby_psi', 'reductedby_xgbregressor'])\n",
        "\n",
        "for i in [reductedby_low_var, '''reductedby_dcor, reductedby_dcor_sqr,''' reductedby_psi, reductedby_xgbregressor]:\n",
        "    print(\"exporting: \", res.columns[i])\n",
        "    sh = gc.create(res.columns[a])\n",
        "    worksheet = gc.open(res.columns[a]).sheet1\n",
        "    cell_list = worksheet.range(1, 1, reducedby_low_var.shape[1], 1)\n",
        "    a = 0\n",
        "    for cell in cell_list:\n",
        "        cell.value = i[a]\n",
        "        a+=1\n",
        "    worksheet.update_cells(cell_list)\n",
        "\n",
        "    \n",
        "rmsle = []    \n",
        "a=0    \n",
        "for i in [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr, reductedby_psi, reductedby_xgbregressor]:\n",
        "    print(\"modeling: \", res.columns[i])    \n",
        "    model = XGBRegressor()\n",
        "    model.fit(i, target_train)\n",
        "    res.iloc[:,a] = model.predict(values_test[i.columns])\n",
        "    rmsle.append(rmsle(target_test, res.iloc[:,a]))\n",
        "    a += 1\n",
        "    \n",
        "print(rmsle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KA-U5oiSime",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = assign_zero(values_train)\n",
        "values_train = normalize(values_train, 0.2)\n",
        "values_test = values_test[values_train.columns]\n",
        "\n",
        "a = reduct_low_var(values_train, 0.001)\n",
        "reductedby_low_var = values_train.drop(a, axis=1)\n",
        "print(\"reductedby_low_var completed: \", a)\n",
        "b = reduct_dcor(values_train, target_train)\n",
        "reductedby_dcor = values_train.drop(b ,axis=1)\n",
        "print(\"reductedby_dcor completed: \", b)\n",
        "c = reduct_dcor_sqr(values_train, target_train)\n",
        "reductedby_dcor_sqr = values_train.drop(c, axis=1)\n",
        "print(\"reductedby_dcor_sqr completed: \", c)\n",
        "d = reduct_psi(values_train, test[values_train.columns])\n",
        "reductedby_psi = values_train.drop(d, axis=1)\n",
        "print(\"reductedby_psi completed: \", d)\n",
        "e = reduct_xgbregressor(values_train, target_train)\n",
        "reductedby_xgbregressor = values_train.drop(e, axis=1)\n",
        "print(\"reductedby_xgbregressor completed: \", e)\n",
        "#f = choose_eliminated(values_train, l2_regularization(values_train, target_train))\n",
        "#reductedby_l2 = values_train.drop(f, axis=1)\n",
        "#print(\"reductedby_l2 completed: \", f)\n",
        "\n",
        "a = 0\n",
        "\n",
        "for i in [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr, reductedby_psi, reductedby_xgbregressor]:\n",
        "    print(\"exporting: \", res.columns[i])\n",
        "    sh = gc.create(res.columns[a])\n",
        "    worksheet = gc.open(res.columns[a]).sheet1\n",
        "    cell_list = worksheet.range(1, 1, i.shape[1], 1)\n",
        "    a = 0\n",
        "    for cell in cell_list:\n",
        "        cell.value = i[a]\n",
        "        a+=1\n",
        "    worksheet.update_cells(cell_list)\n",
        "\n",
        "lll = [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr, reductedby_psi, reductedby_xgbregressor]\n",
        "\n",
        "fin = pd.DataFrame(np.ones([len(values.columns),len(lll)]))\n",
        "fin.index = values.columns\n",
        "fin.columns = ['reductedby_low_var', 'reductedby_dcor', 'reductedby_dcor_sqr', 'reductedby_psi', 'reductedby_xgbregressor']\n",
        "\n",
        "a = 0\n",
        "for l in lll:\n",
        "    fin.iloc[l.columns,a] = np.zeros(len(l.columns))\n",
        "    a+=1\n",
        "    \n",
        "sh = gc.create('fin')\n",
        "worksheet = gc.open('fin').sheet1\n",
        "for z in range(len(lll)):\n",
        "    cell_list = worksheet.range(1, z+1, fin.shape[1], z+1)\n",
        "    a = 0\n",
        "    for cell in cell_list:\n",
        "        cell.value = fin.iloc[a,z]\n",
        "        a+=1\n",
        "\n",
        "        worksheet.update_cells(cell_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yUBnD_HYWfy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - An object to be used as a cross-validation generator.\n",
        "          - An iterable yielding train/test splits.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : integer, optional\n",
        "        Number of jobs to run in parallel (default 1).\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "title = \"Learning Curves\"\n",
        "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
        "\n",
        "estimator = XGBRegressor()\n",
        "plot_learning_curve(estimator, title, values_train, target_train, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
        "\n",
        "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
        "# SVC is more expensive so we do a lower number of CV iterations:\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "estimator = SVC(gamma=0.001)\n",
        "plot_learning_curve(estimator, title, values_train, target_train, (0.7, 1.01), cv=cv, n_jobs=4)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5qM8HTzMfkR",
        "colab_type": "code",
        "outputId": "b79f51d2-ed92-4cd4-aa06-ed286b5071ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "lis =  ['reductedby_low_var', 'reductedby_dcor', 'reductedby_dcor_sqr']\n",
        "for i in [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr]:\n",
        "    sh = gc.create(lis[t])\n",
        "    worksheet = gc.open(lis[t]).sheet1\n",
        "    cell_list = worksheet.range(1, 1, i.shape[1], 1)\n",
        "    a = 0\n",
        "    for cell in cell_list:\n",
        "        cell.value = i.columns[a]\n",
        "        a+=1\n",
        "    worksheet.update_cells(cell_list)\n",
        "    t+=1\n",
        "\n",
        "lll = [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr]\n",
        "\n",
        "fin = pd.DataFrame(np.ones([len(values.columns),len(lll)]))\n",
        "fin.index = values.columns\n",
        "fin.columns = lis\n",
        "\n",
        "a = 0\n",
        "for l in lll:\n",
        "    fin.loc[l.columns, [lis[a]]] = 0\n",
        "    a+=1\n",
        "    \n",
        "sh = gc.create('fin')\n",
        "worksheet = gc.open('fin').sheet1\n",
        "for z in range(len(lll)):\n",
        "    cell_list = worksheet.range(1, z+1, fin.shape[0], z+1)\n",
        "    a = 0\n",
        "    for cell in cell_list:\n",
        "        cell.value = fin.iloc[a,z]\n",
        "        a+=1\n",
        "\n",
        "        worksheet.update_cells(cell_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-bc52c31235f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'reductedby_low_var'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reductedby_dcor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reductedby_dcor_sqr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreductedby_low_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreductedby_dcor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreductedby_dcor_sqr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mworksheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcell_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mDRIVE_FILES_API_V2_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    209\u001b[0m         \u001b[0mspreadsheet_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_spreadsheet_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIError\u001b[0m: {\n \"error\": {\n  \"errors\": [\n   {\n    \"domain\": \"global\",\n    \"reason\": \"authError\",\n    \"message\": \"Invalid Credentials\",\n    \"locationType\": \"header\",\n    \"location\": \"Authorization\"\n   }\n  ],\n  \"code\": 401,\n  \"message\": \"Invalid Credentials\"\n }\n}\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "h5DyfPK2dSpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "fin.to_csv('fin.csv')\n",
        "files.download('fin.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6E4NuY6f7zS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = assign_zero(values_train)\n",
        "values_train = normalize(values_train, 0.2)\n",
        "values_test = values_test[values_train.columns]\n",
        "\n",
        "a = reduct_low_var(values_train, 0.001)\n",
        "reductedby_low_var = values_train.drop(a, axis=1)\n",
        "'''b = reduct_dcor(values_train, target_train)\n",
        "reductedby_dcor = values_train.drop(b ,axis=1)\n",
        "c = reduct_dcor_sqr(values_train, target_train)\n",
        "reductedby_dcor_sqr = values_train.drop(c, axis=1)'''\n",
        "d = reduct_psi(values_train, test[values_train.columns], thresh=0.25)\n",
        "reductedby_psi = values_train.drop(d, axis=1)\n",
        "e = reduct_xgbregressor(values_train, target_train)\n",
        "reductedby_xgbregressor = values_train.drop(e, axis=1)\n",
        "\n",
        "#f = choose_eliminated(values_train, l2_regularization(values_train, target_train))\n",
        "#reductedby_l2 = values_train.drop(f, axis=1)\n",
        "#print(\"reductedby_l2 completed: \", f)\n",
        "\n",
        "lis = ['reductedby_low_var', 'reductedby_psi', 'reductedby_xgbregressor', 'reductedby_dcor', 'reductedby_dcor_sqr']\n",
        "lll = [reductedby_low_var, reductedby_psi, reductedby_xgbregressor]\n",
        "\n",
        "fin = pd.DataFrame(np.ones([len(values.columns),5]))\n",
        "fin.index = values.columns\n",
        "fin.columns = lis\n",
        "fin['reductedby_dcor'] = np.array(reds['reductedby_dcor'])\n",
        "fin['reductedby_dcor_sqr'] = np.array(reds['reductedby_dcor_sqr'])\n",
        "\n",
        "a = 0\n",
        "for l in lll:\n",
        "    fin.loc[l.columns, [lis[a]]] = 0\n",
        "    a+=1\n",
        "    \n",
        "fin.to_csv('fin.csv')\n",
        "files.download('fin.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ypaQBY3hl5Hz",
        "colab_type": "code",
        "outputId": "6e108d98-d962-4d2e-e44a-eb57b6dde811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5eb224f5-249e-44e3-aebd-19aecd616898\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5eb224f5-249e-44e3-aebd-19aecd616898\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dimensionality reduction.csv to dimensionality reduction.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X10A29AevfX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "reds = pd.read_csv(io.StringIO(uploaded['dimensionality reduction.csv'].decode('utf-8')))\n",
        "#reds.index = reds.iloc[:,0]\n",
        "\n",
        "#a = [i for i in reds.index if reds.loc[i,'reductedby_low_var']==0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzN-adgE-emZ",
        "colab_type": "code",
        "outputId": "c2a48ecd-e95a-4a56-825e-278ab119276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1201
        }
      },
      "cell_type": "code",
      "source": [
        "print(values_train['cde9c35e8'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cde9c35e8'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-39d0188106dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cde9c35e8'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cde9c35e8'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sLQSyvYIw-eL",
        "colab_type": "code",
        "outputId": "19d86f36-5d43-4220-fb4e-189640c1acf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "cell_type": "code",
      "source": [
        "#from xgboost import XGBRegressor\n",
        "\n",
        "#values, target = get_data(train)\n",
        "#values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "#values_train = assign_zero(values_train)\n",
        "#values_train = normalize(values_train, 0.2)\n",
        "#values_test = values_test[values_train.columns]\n",
        "\n",
        "model = XGBRegressor()\n",
        "\n",
        "model.fit(values_train[a], target_train)\n",
        "res = model.predict(values_test[a])\n",
        "rmsle_ = rmsle(target_test.tolist(), res)\n",
        "\n",
        "print(rmsle_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-6da4e60e46b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrmsle_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['e90ed19da' 'f5f97a9e8' '7497a6bc9' 'bfde2aa61' '9abaeaeba' 'e7fa14f98'\\n 'a47434e94' '78f7fcebd' '8405c17e7' '0c8e0cd38' '30cef4483'] not in index\""
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "raJreATZCmL8",
        "colab_type": "code",
        "outputId": "ace24591-fc46-4cfb-844a-3cb29d7aaf60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "a = [i for i in fin.index if fin.loc[i,'reductedby_dcor']==0]\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['20aa07010', 'bd8f989f1', '87ffda550', 'ea18d720e', '1e8801477', 'c1b9f4e76', 'c2cabb902', '47cd6e6e4', '15e8a9331', 'aa31dd768', '6c4f594e0', 'a31ba11e6', 'ce8ce671e', '0572565c2', '66ace2992', 'd833db6e1', 'b2790ef54', 'a1f9d1680', '6786ea46d', 'bc70cbc26', '4b6dfc880', 'c7525612c', 'ca96df1db', '64e483341', 'ac7a97382', '2b54cddfd', '994b946ad', '55741d46d', '64dd02e44', 'e4159c59e', 'f3cf9341c', '371da7669', '00f844fea', '8c0a1fa32', 'b43a7cfd5', '7af000ac2', '0a953f97e', 'dda820122', '5f341a818', '9884166a7', 'ccd9fc164', 'c91a4f722', '5fe3acd24', '438b8b599', '080cd72ff', '939cc02f5', '73e591019', '61a0acefa', '7f55b577c', '241f0f867', '1eec37deb', '6ff9b1760', 'f02ecb19c', '621833d9b', 'db147ffca', '58e2e02e6', '4fe8154c8', '03055cc36', '3e1100230', '119230239', '54723be01', 'ba4ceabc5', 'adf03173b', '74d7998d4', '5a798adc1', '122c135ed', '43ebb15de', '16bf5a9a2', '3f4a39818', 'eeb9cd3aa', 'a029667de', '01005e5de', '7a7da3079', '58232a6fb', 'c0d2348b7', 'cef9ab060', '70feb1494', '3ce93a21b', '6192f193d', 'fa1dd6e8c', '8a1b76aaf', 'bb0ce54e9', '18c35d2ea', '758a9ab0e', 'f190486d6', 'c4972742d', '9a07d7b1f', '77deffdf0', 'c5a231d81', '13d6a844f', '2b6f74f09', '8d12d44e1', '96b66294d', 'bca395b73', '95aea9233', 'e04141e42', 'c47340d97', '762cbd0ab', 'c03c8799c', 'acc4a8e68']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8BF31Ul_qqc1",
        "colab_type": "code",
        "outputId": "551df772-6d36-4540-d18e-c4915df6c1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rmsl = []    \n",
        "res = pd.DataFrame(columns = ['reductedby_low_var',  'reductedby_psi', 'reductedby_xgbregressor', 'reductedby_dcor', 'reductedby_dcor_sqr', 'values_train', 'aaa'])\n",
        "a=0\n",
        "reductedby_dcor = values_train[[i for i in fin.index if fin.loc[i,'reductedby_dcor']==0]]\n",
        "reductedby_dcor_sqr = values_train[[i for i in fin.index if fin.loc[i,'reductedby_dcor_sqr']==0]]\n",
        "aaa, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "for i in [reductedby_low_var, reductedby_dcor, reductedby_dcor_sqr, reductedby_psi, reductedby_xgbregressor, values_train, aaa]:   \n",
        "    model = XGBRegressor()\n",
        "    model.fit(i, target_train)\n",
        "    res.iloc[:,a] = model.predict(values_test[i.columns])\n",
        "    rmsl.append(rmsle(target_test.tolist(), res.iloc[:,a].tolist()))\n",
        "    a += 1\n",
        "    \n",
        "print(rmsl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.8782197916844297, 2.4393494768812647, 2.4453312810294867, 2.6544677878199687, 2.3899850893656436, 2.8782197916844297, 1.8588001952547586]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lz1-Lr6Z7-bY",
        "colab_type": "code",
        "outputId": "b899885a-b9e8-4e95-e5b6-725d773874a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "rmsl = 5\n",
        "n_opt_j = -1\n",
        "n_opt_i = -1\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = values_train.fillna(0)\n",
        "\n",
        "corr = np.zeros([len(values_train.columns),2])\n",
        "    \n",
        "for i in range(len(values_train.columns)):\n",
        "    corr[i,:] = np.array([i, dcor.u_distance_correlation_sqr(values_train.iloc[:,i], target_train)])\n",
        "    \n",
        "for j in range(5):\n",
        "    thresh = np.nanpercentile(corr[:,1], 10+(4*j))\n",
        "    corr_new = np.array([i for i in corr if i[1] >= thresh])   \n",
        "    for i in range(7):\n",
        "        n_features = 4*(2**i)\n",
        "        if n_features > len(corr_new):\n",
        "            features_chosen = values_train.columns[corr_new[:,0]]\n",
        "            features_eliminated = choose_eliminated(values_train, features_chosen)\n",
        "            re = values_train.drop(features_eliminated, axis = 1)\n",
        "           \n",
        "        else:     \n",
        "            kmeans = km(n_clusters = n_features).fit(corr_new[:,1].reshape(-1,1))\n",
        "            labels = kmeans.labels_\n",
        "\n",
        "            x=[]\n",
        "            for l in range(n_features):\n",
        "                x.append([m for m,d in enumerate(labels) if d==l])\n",
        "            features_chosen = np.zeros(n_features)\n",
        "            features_chosen = features_chosen-1\n",
        "            maxx = np.zeros(n_features)\n",
        "            for l in range(len(labels)):\n",
        "                a = abs(dcor.u_distance_correlation_sqr(values_train.iloc[:,x[labels[l]]], values_train.iloc[:,int(corr_new[l,0])]))\n",
        "                if a >= maxx[labels[l]]:\n",
        "                    maxx[labels[l]] = a\n",
        "                    features_chosen[labels[l]] = corr_new[l,0]\n",
        "            features_chosen = np.array([int(z) for z in features_chosen if z>=0])\n",
        "            features_chosen = values.columns[features_chosen]\n",
        "            features_eliminated = choose_eliminated(values_train, features_chosen)   \n",
        "            re = values_train.drop(features_eliminated, axis = 1)\n",
        "            \n",
        "        model = XGBRegressor()\n",
        "        model.fit(re, target_train)\n",
        "        pred = model.predict(values_test[re.columns])\n",
        "        score = rmsle(target_test.tolist(), pred.tolist())\n",
        "        if rmsl > score:\n",
        "            rmsl = score\n",
        "            n_opt_i = i\n",
        "            n_opt_j = j\n",
        "        print(rmsl, n_opt_i, n_opt_j)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dcor/_dcor.py:718: RuntimeWarning: overflow encountered in long_scalars\n",
            "  d_cov = (aijbij / n / (n - 3) - 2 * sum_ab / n / (n - 2) / (n - 3) +\n",
            "/usr/local/lib/python3.6/dist-packages/dcor/_dcor.py:718: RuntimeWarning: overflow encountered in longlong_scalars\n",
            "  d_cov = (aijbij / n / (n - 3) - 2 * sum_ab / n / (n - 2) / (n - 3) +\n",
            "/usr/local/lib/python3.6/dist-packages/dcor/_utils.py:88: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  return ((np.issubdtype(x.dtype, float) and\n",
            "/usr/local/lib/python3.6/dist-packages/dcor/_utils.py:90: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  (np.issubdtype(x.dtype, int) and\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "u4v0XD3IuJS9",
        "colab_type": "code",
        "outputId": "69bfdaf3-69c9-4f74-f7fb-243d32a1151b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import explained_variance_score as evs\n",
        "evs()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 -1 -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFqWjmCrwyo6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV as rfe\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "selector = rfe(XGBRegressor(), cv=cv, scoring = 'mean_squared_log_error')\n",
        "values_train = selector.fit_transform(values_train, target_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQije3dtygiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "#values_train = values_train.fillna(0)\n",
        "\n",
        "#corr = np.zeros([len(values_train.columns),2])\n",
        "    \n",
        "#for i in range(len(values_train.columns)):\n",
        "#    corr[i,:] = np.array([i, dcor.u_distance_correlation_sqr(values_train.iloc[:,i], target_train)])\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GbDZ0cbJSkr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = np.where(corr[:,1] == max(corr[:,1]))\n",
        "kmeans = KMeans(values_train['target'])\n",
        "values_train[a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZoRNHGMq9PK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thresh = max(np.nanpercentile(corr[:,1], 10), ((max(corr[:,1])-min(corr[:,1]))*0.1)+min(corr[:,1]))\n",
        "corr_new = np.array([i for i in corr if i[1] >= thresh])\n",
        "values_train_new = values_train.iloc[:,corr_new[:,0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dF1NT8Q2oKf",
        "colab_type": "code",
        "outputId": "bfd4eb96-4904-4476-b7ac-98a46634fb55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "thresh = max(np.nanpercentile(corr[:,1], 10), ((max(corr[:,1])-min(corr[:,1]))*0.1)+min(corr[:,1]))\n",
        "corr_new = np.array([i for i in corr if i[1] >= thresh])\n",
        "corr_new.shape\n",
        "\n",
        "kmeans = km(n_clusters = 8).fit(corr_new[:,1].reshape(-1,1))\n",
        "labels = kmeans.labels_\n",
        "\n",
        "x=[]\n",
        "for l in range(8):\n",
        "    x.append([i for i,d in enumerate(labels) if d==l])\n",
        "\n",
        "features_chosen = np.zeros(8)\n",
        "features_chosen = features_chosen-1\n",
        "maxx = np.zeros(8)\n",
        "for l in range(len(labels)):\n",
        "    a = abs(dcor.u_distance_correlation_sqr(values.iloc[:,x[labels[l]]], values.iloc[:,int(corr[l,0])]))\n",
        "    if a >= maxx[labels[l]]:\n",
        "        maxx[labels[l]] = a\n",
        "        features_chosen[labels[l]] = corr[l,0]\n",
        "\n",
        "features_chosen = np.array([int(i) for i in features_chosen if i>=0])\n",
        "features_chosen = values_train.columns[features_chosen]\n",
        "features_eliminated = choose_eliminated(values_train, features_chosen)   \n",
        "re = values_train.drop(features_eliminated, axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dcor/_utils.py:88: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  return ((np.issubdtype(x.dtype, float) and\n",
            "/usr/local/lib/python3.6/dist-packages/dcor/_utils.py:90: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  (np.issubdtype(x.dtype, int) and\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I_naM1QESLcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "re_new = PolynomialFeatures(5).fit_transform(re)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WH33QnN9jyMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corr_re_new = np.zeros([re_new.shape[1],2])\n",
        "    \n",
        "for i in range(re_new.shape[1]):\n",
        "    corr_re_new[i,:] = np.array([i, dcor.u_distance_correlation_sqr(re_new[:,i], target_train)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GoIQkhpltpr",
        "colab_type": "code",
        "outputId": "e258b88f-62ed-429e-fbd2-3b94decd3c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "thresh = max(np.nanpercentile(corr_re_new[:,1], 3), ((max(corr_re_new[:,1])-min(corr_re_new[:,1]))*0.03)+min(corr_re_new[:,1]))\n",
        "corr_re_new_new = np.array([i for i in corr_re_new if i[1] >= thresh])\n",
        "corr_re_new_new.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "metadata": {
        "id": "JHAe--Qe4QnQ",
        "colab_type": "code",
        "outputId": "42a444ae-2628-4ba9-d059-7a0cda8d61da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "            \n",
        "model = XGBRegressor()\n",
        "target_train_new = target_train.apply(lambda x: math.log(x))\n",
        "model.fit(values_train_new.iloc[:,np.array([int(i) for i in corr_new[:,0]])], target_train_new)\n",
        "pred = model.predict(values_test[values_train_new.columns])[:,np.array([int(i) for i in corr_new[:,0]])]\n",
        "pred = [math.pow(math.e,i) for i in pred]\n",
        "score = rmsle(target_test.tolist(), pred)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d2bacbd8e5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorr_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorr_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[1;32m    206\u001b[0m                                  \u001b[0;34m\"[{types}] types\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1672\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_list_like\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1729\u001b[0m         if (hasattr(arr, '__len__') and len(arr) and\n\u001b[1;32m   1730\u001b[0m                 (arr.max() >= l or arr.min() < -l)):\n\u001b[0;32m-> 1731\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "q1QRuIcmAz2-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(test[re.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAncqzoaCK7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = [math.pow(math.e,i) for i in pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtIzuS2UCQcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(columns=['target'])\n",
        "\n",
        "submission['target'] = np.array(pred)\n",
        "submission.index = test['ID']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZbJXWxfEFsa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('submission.csv')\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jw28sObcP372",
        "colab_type": "code",
        "outputId": "897d9b97-a0d3-4312-f80e-cff930989cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4962591240035366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qlwt_p3K1mnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import math\n",
        "#from lightgbm import LGBMRegressor as gbm\n",
        "#from xgboost import XGBRegressor as xgb\n",
        "#from sklearn.preprocessing import StandardScaler as ss\n",
        "#from sklearn.cross_validation import train_test_split as tts\n",
        "#from sklearn.linear_model import ElasticNet as el\n",
        "from catboost import CatBoostRegressor as cbr\n",
        "\n",
        "score = 0\n",
        "for t in range(50):\n",
        "    values, target = get_data(train)\n",
        "    values = values[bins]\n",
        "    values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "    values_train = assign_zero(values_train)\n",
        "\n",
        "    #model = gbm()\n",
        "    #ress = target_train.apply(lambda x: math.log(x))\n",
        "    #model.fit(values_train, ress)\n",
        "    #pred1 = model.predict(values_test[values_train.columns])\n",
        "    #pred1 = [np.exp(i) for i in pred1]\n",
        "\n",
        "    #model = xgb()\n",
        "    #ress = target_train.apply(lambda x: math.log(x))\n",
        "    #model.fit(values_train, ress)\n",
        "    #pred2 = model.predict(values_test[values_train.columns])\n",
        "    #pred2 = [np.exp(i) for i in pred2]\n",
        "    \n",
        "    model = cbr()\n",
        "    ress = target_train.apply(lambda x: math.log1p(x))\n",
        "    model.fit(values_train, ress)\n",
        "    pred4 = model.predict(values_test[values_train.columns])\n",
        "    pred4 = [np.expm1(i) for i in pred4]\n",
        "    \n",
        "    #model = el(no)\n",
        "    #ress = target_train.apply(lambda x: math.log(x))\n",
        "    #model.fit(values_train, ress)\n",
        "    #pred3 = model.predict(values_test[values_train.columns])\n",
        "    #pred3 = [np.exp(i) for i in pred3]\n",
        "\n",
        "    #pred = []\n",
        "    #for i in range(len(pred1)):\n",
        "    #    pred.append(pred1[i]*0.5+pred2[i]*0.5)\n",
        "\n",
        "    score += rmsle(target_test.tolist(),pred4)\n",
        "\n",
        "print(score/50)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_BMAIVwBq-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(values[values_train.columns], ress)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5LuNOGZPj4k",
        "colab_type": "code",
        "outputId": "c8bb334c-4e35-42ed-cff8-a410b1243c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10132331.346310161, 448443.3886699506, 49764.60436018957, 2159010.5464504506, 165866.75976811588, 24655111.10368071, 1016808.6997241376, 4613801.104079604]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rWizeIZ6LSH8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import math\n",
        "from xgboost import XGBRegressor as xgb\n",
        "\n",
        "\n",
        "minscore = 10\n",
        "opteps = 0\n",
        "for i in range(300):\n",
        "    eps = 0.25 + i*0.001\n",
        "    values, target = get_data(train)\n",
        "    values = values.fillna(0)\n",
        "    col = values.columns\n",
        "    values = reduct_sparse_rp(values, eps)\n",
        "    values = pd.DataFrame(values)\n",
        "    values.columns = col[:values.shape[1]]\n",
        "    values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "\n",
        "    ress = target_train.apply(lambda x: math.log(x))\n",
        "\n",
        "    model = xgb()\n",
        "    model.fit(values_train, ress)\n",
        "    pred = model.predict(values_test)\n",
        "    pred = [math.e**i for i in pred]\n",
        "    score = rmsle(target_test.tolist(),pred)\n",
        "    if score < minscore:\n",
        "        minscore = score\n",
        "        opteps = eps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSl5kt8EL-NY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(test.iloc[:,1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4l5-Kved1dI",
        "colab_type": "code",
        "outputId": "37120846-747a-414b-f825-1f00292a09e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import math\n",
        "from xgboost import XGBRegressor as xgb\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_ = values.fillna(0)\n",
        "test_ = test\n",
        "test_ = test_.fillna(0)\n",
        "col = values.columns\n",
        "len_val = values.shape[0]\n",
        "temp = pd.concat([values_, test_.iloc[:,1:]], axis=0)\n",
        "\n",
        "minscore = 10\n",
        "opteps = 0\n",
        "for i in range(50):\n",
        "    eps = 0.25 + i*0.006\n",
        "    temp_ = reduct_sparse_rp(temp, eps)\n",
        "    temp_ = pd.DataFrame(temp_)\n",
        "    values_ = temp_.iloc[:len_val,:]\n",
        "    test_ = temp_.iloc[len_val:,:]\n",
        "    me=0\n",
        "    for t in range(5):\n",
        "        values_train, values_test, target_train, target_test = tts(values_, target, test_size=0.2)\n",
        "        ress = target_train.apply(lambda x: math.log(x))\n",
        "        model = xgb()\n",
        "        model.fit(values_train, ress)\n",
        "        pred = model.predict(values_test)\n",
        "        pred = [math.e**i for i in pred]\n",
        "        for i in range(len(pred)):\n",
        "            a = values_test.iloc[i,:]\n",
        "            for j in range(values_test.shape[1]):\n",
        "                if (pred[i] >= 0.9*values_test.iloc[i,j]) & (pred[i] <= 1.1*values_test.iloc[i,j]):\n",
        "                    pred[i] = values_test.iloc[i,j]\n",
        "                    j = values_test.shape[1]-1\n",
        "        score = rmsle(target_test.tolist(), pred)\n",
        "        me += score\n",
        "    if me < minscore*5:\n",
        "        minscore = me/5\n",
        "        opteps = eps\n",
        "         \n",
        "    print(me,eps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.458747287579866 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dc6f312c5afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             key = tuple(com._apply_if_callable(x, self.obj)\n\u001b[0;32m-> 1361\u001b[0;31m                         for x in key)\n\u001b[0m\u001b[1;32m   1362\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             key = tuple(com._apply_if_callable(x, self.obj)\n\u001b[0;32m-> 1361\u001b[0;31m                         for x in key)\n\u001b[0m\u001b[1;32m   1362\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_apply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \"\"\"\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jKzcUlta7-S2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import math\n",
        "from xgboost import XGBRegressor as xgb\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_ = values.fillna(0)\n",
        "test_ = test\n",
        "test_ = test_.fillna(0)\n",
        "col = values.columns\n",
        "len_val = values.shape[0]\n",
        "temp = pd.concat([values_, test_.iloc[:,1:]], axis=0)\n",
        "\n",
        "temp_ = reduct_sparse_rp(temp, 0.256)\n",
        "temp_ = pd.DataFrame(temp_)\n",
        "values_ = temp_.iloc[:len_val,:]\n",
        "test_ = temp_.iloc[len_val:,:]\n",
        "ress = target.apply(lambda x: math.log(x))\n",
        "model = xgb()\n",
        "model.fit(values_, ress)\n",
        "pred = model.predict(test_)\n",
        "pred = [math.e**i for i in pred]\n",
        "\n",
        "for i in range(len(pred)):\n",
        "    a = test_.iloc[i,:]\n",
        "    for j in range(test_.shape[1]):\n",
        "       if (pred[i] >= 0.95*test_.iloc[i,j]) & (pred[i] <= 1.05*test_.iloc[i,j]):\n",
        "          pred[i] = test_.iloc[i,j]\n",
        "          j = test_.shape[1]-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQfMLZgsuHIH",
        "colab_type": "code",
        "outputId": "455961ba-0f72-4175-c9fb-d7a8d704e3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "wQBrzIwoqei0",
        "colab_type": "code",
        "outputId": "0b62b1ae-f7d8-4fb7-903b-601a11433327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import math\n",
        "from lightgbm import LGBMRegressor as lgbm\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "values, target = get_data(train)\n",
        "values = values[a]\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = assign_zero(values_train)\n",
        "values_test = values_test[values_train.columns]\n",
        "\n",
        "corr = np.zeros([len(values_train.columns),2])\n",
        "    \n",
        "for i in range(len(values_train.columns)):\n",
        "    corr[i,:] = np.array([i, dcor.u_distance_correlation_sqr(values_train.iloc[:,i], target_train)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dcor/_dcor.py:718: RuntimeWarning: overflow encountered in long_scalars\n",
            "  d_cov = (aijbij / n / (n - 3) - 2 * sum_ab / n / (n - 2) / (n - 3) +\n",
            "/usr/local/lib/python3.6/dist-packages/dcor/_dcor.py:718: RuntimeWarning: overflow encountered in longlong_scalars\n",
            "  d_cov = (aijbij / n / (n - 3) - 2 * sum_ab / n / (n - 2) / (n - 3) +\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lko9gSIfi5XT",
        "colab_type": "code",
        "outputId": "8568deb6-7675-4ef7-bb89-745ada07f179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#thresh = max(np.nanpercentile(corr_re_new[:,1], 3), ((max(corr_re_new[:,1])-min(corr_re_new[:,1]))*0.03)+min(corr_re_new[:,1]))\n",
        "thresh = 0.08\n",
        "corr = np.array([i for i in corr if i[1] >= thresh])\n",
        "print(corr.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tAJPA0kiBPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feat = np.array([int(i) for i in corr[:,0]])\n",
        "classy = pd.DataFrame(columns = values_train.columns[feat])\n",
        "\n",
        "target_train_log = target_train.apply(lambda x: math.log(x))\n",
        "classy['target_train'] = (target_train_log - target_train_log.mean())/target_train_log.std()\n",
        "for i in range(len(classy['target_train'])):\n",
        "    if classy.loc['target_train',i]>3:\n",
        "        p3.append()\n",
        "\n",
        "for i in classy:\n",
        "    classy[i] = (values_train[i] - values_train[i].mean())/values_train[i].std()\n",
        "    \n",
        "classy_test = pd.DataFrame(columns = values_train.columns[feat])\n",
        "for i in classy_test:\n",
        "    classy_test[i] = (values_test[i] - values_test[i].mean())/values_test[i].std()\n",
        "\n",
        "\n",
        "#kmeans = km(n_clusters = n_features).fit(target_train.apply(lambda x: math.log(x)).reshape(-1,1))  #n_features should be determined based on a performance metrics\n",
        "#labels = kmeans.labels_\n",
        "\n",
        "target_test_log = target_test.apply(lambda x: math.log(x))\n",
        "target_test_log = (target_test_log - target_test_log.mean())/target_test_log.std() \n",
        "\n",
        "model = lgbm()\n",
        "model.fit(classy.drop(['target_train'], axis=1), classy['target_train'])\n",
        "pred = model.predict(classy_test)\n",
        "#pred = [math.e**i for i in pred]\n",
        "score = r2(target_test_log,pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4CbZqlEg7aZ",
        "colab_type": "code",
        "outputId": "4f8b36c0-6347-4b50-e0bb-572fc589130f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "print(values_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5cdeae87eb87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'values_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "o6G7NBXR46or",
        "colab_type": "code",
        "outputId": "ca483384-f51c-44a0-dbe6-bb27d24a280e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1118
        }
      },
      "cell_type": "code",
      "source": [
        "values_test['f190486d6']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4389           0.00\n",
              "3910     5352666.66\n",
              "2665           0.00\n",
              "3396      570000.00\n",
              "3234           0.00\n",
              "2576       60000.00\n",
              "1028    40833333.34\n",
              "2487           0.00\n",
              "1051           0.00\n",
              "1438        7000.00\n",
              "927            0.00\n",
              "1354           0.00\n",
              "3820     7900000.00\n",
              "2339           0.00\n",
              "47             0.00\n",
              "4188    20000000.00\n",
              "138            0.00\n",
              "1000           0.00\n",
              "4255           0.00\n",
              "3158           0.00\n",
              "1957     2352000.00\n",
              "3600           0.00\n",
              "3564           0.00\n",
              "2489           0.00\n",
              "1556           0.00\n",
              "498     12218000.00\n",
              "525            0.00\n",
              "3131    14190000.00\n",
              "1387           0.00\n",
              "3480           0.00\n",
              "           ...     \n",
              "1805     3200000.00\n",
              "224            0.00\n",
              "249            0.00\n",
              "4413           0.00\n",
              "393            0.00\n",
              "2264     1260000.00\n",
              "2882     3952000.00\n",
              "793      4000000.00\n",
              "2806     5000000.00\n",
              "3408           0.00\n",
              "1201           0.00\n",
              "3553           0.00\n",
              "2017           0.00\n",
              "3203           0.00\n",
              "3678           0.00\n",
              "3677           0.00\n",
              "2531           0.00\n",
              "3490           0.00\n",
              "3857     5000000.00\n",
              "600            0.00\n",
              "2643           0.00\n",
              "3208           0.00\n",
              "281            0.00\n",
              "4037    10000000.00\n",
              "577            0.00\n",
              "301            0.00\n",
              "1164           0.00\n",
              "3874           0.00\n",
              "2388     2000000.00\n",
              "2128           0.00\n",
              "Name: f190486d6, Length: 892, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "o5P649yIf6Vm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "reds = pd.read_csv(io.StringIO(uploaded['dimensionality reduction.csv'].decode('utf-8')))\n",
        "reds.index = reds.iloc[:,0]\n",
        "\n",
        "a = [i for i in reds.index if (reds.loc[i,'reductedby_low_var']==0) & (reds.loc[i,'reductedby_xgbregressor']==0.0) & (reds.loc[i,'reductedby_psi']==0.0)]\n",
        "a = a[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5eXNHqPuXx4_",
        "colab_type": "code",
        "outputId": "eb046e73-1bfa-4615-c95c-a31a51c8368e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#values_train_new.iloc[4,:]=np.array([int(i) for i in values_train.iloc[4,:]==target_train.iloc[4]])\n",
        "#print(sum(values_train_new.iloc[4,:]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3567, 4668)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "YurKFdv6HqBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split as tts\n",
        "from sklearn.linear_model import LogisticRegression as lr\n",
        "\n",
        "values, target = get_data(train)\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = assign_zero(values_train)\n",
        "values_test = values_test[values_train.columns]\n",
        "\n",
        "dec = []\n",
        "nm = []\n",
        "values_train_new = values_train\n",
        "for k in range(values_train.shape[0]):\n",
        "    values_train_new.iloc[k,:] = np.array([int(i) for i in values_train.iloc[k,:]==target_train.iloc[k]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBnv2CsWHzOy",
        "colab_type": "code",
        "outputId": "67148c2c-4f5c-401d-c581-c7be4f0151d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "perm = values_train_new\n",
        "temp = values_train_new\n",
        "freq = values_train_new.sum(axis=1)\n",
        "while freq.sum()>0:\n",
        "    inn = freq[freq==max(freq)].index[0]\n",
        "    tar_train = perm.iloc[:,inn]\n",
        "    part_train = values_train.drop(values_train.columns[inn], axis=1)\n",
        "    part_test = values_test.drop(values_train.columns[inn], axis=1)\n",
        "    temp = temp.drop((temp.iloc[:,inn]==1).index, axis=0)\n",
        "    freq = temp.sum(axis=1)\n",
        "    model = lr()\n",
        "    model.fit(part_train, tar_train)\n",
        "    dec.append(model.predict_proba(part_test))\n",
        "    nm.append(values_train.columns[inn])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
            "  np.exp(prob, prob)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xGemYb5r07Ag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from sklearn.feature_selection import RFECV as rfe\n",
        "#from sklearn.model_selection import ShuffleSplit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.cross_validation import train_test_split as tts\n",
        "import math\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "#from sklearn.ensemble import RandomForestRegressor as rf\n",
        "\n",
        "#train = pd.read_csv(r'C:\\Users\\StjYahyaG\\reduction\\train.csv')\n",
        "values = train.iloc[:,2:]\n",
        "col = values.columns\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "values = pd.DataFrame(scaler.fit_transform(values))\n",
        "values.columns = col\n",
        "target = train.iloc[:,1]\n",
        "scaler2 = MinMaxScaler(feature_range=(-1, 1))\n",
        "target = scaler2.fit_transform(target.values.reshape(-1, 1))\n",
        "\n",
        "#cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "#selector = rfe(rf(), cv=cv, scoring = scorer(msle(),values_train, target_train))\n",
        "#values = selector.fit_transform(values, target)\n",
        "#from tsfresh import extract_features\n",
        "\n",
        "#from lightgbm import LGBMRegressor as lgbm\n",
        "\n",
        "\n",
        "#col = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7' ,'1931ccfdd', '703885424' ,'70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', '6619d81fc', '1db387535']\n",
        "values_train, values_test, target_train, target_test = tts(values, target, test_size=0.2)\n",
        "values_train = values_train.dropna(thresh=int(values_train.shape[1]*0.95))\n",
        "values_train = values_train.fillna(0)\n",
        "values_train = values_train.drop([i for i in values_train.columns if values_train[i].sum()==0], axis = 1)\n",
        "#values_train_new = pd.DataFrame(np.array(values_train).reshape(values_train.shape[0], 1, values_train.shape[1]))\n",
        "#values_train_new.columns = col\n",
        "values_test = values_test[values_train.columns]\n",
        "#new_features_train = extract_features(values_train['f190486d6'])\n",
        "#fin = pd.concat(values_train, new_features_train, axis=1)\n",
        "#new_features_test = extract_features(values_test['f190486d6'], column_id='bla')\n",
        "#values_test_fin = pd.concat(values_test, new_features_test, axis=1)\n",
        "\n",
        "#target_train_log = target_train.apply(lambda x: math.log(x))\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(values_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer='Adam', metrics=['accuracy'])\n",
        "model_info = model.fit(values_train, target_train, epochs = 100, validation_split=0.2)\n",
        "plot_model_history(model_info)\n",
        "\n",
        "pred = model.predict(values_test)\n",
        "pred = scaler2.inverse_transform(pred)\n",
        "#pred = [math.e**i for i in pred]\n",
        "\n",
        "score = rmsle(target_test.tolist(), pred.tolist())\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGE5HSK-JH3p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_model_history(model_info)\n",
        "\n",
        "pred = model.predict(values_test)\n",
        "pred = scaler2.inverse_transform(pred)\n",
        "#pred = [math.e**i for i in pred]\n",
        "\n",
        "score = rmsle(target_test.tolist(), pred.tolist())\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JO7JSHExnini",
        "colab_type": "code",
        "outputId": "eebff26e-ec2b-478e-a6f5-e972bb8dd781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(values_train).reshape(values_train.shape[0], 1, values_train.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -1.        , -1.        ]],\n",
              "\n",
              "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -1.        , -1.        ]],\n",
              "\n",
              "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -0.90286232, -1.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -1.        , -1.        ]],\n",
              "\n",
              "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -1.        , -1.        ]],\n",
              "\n",
              "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
              "         -1.        , -1.        ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "LOvV3Idbms-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}